<html>
<head>
	<meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Squats</title>
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" integrity="sha384-zCbKRCUGaJDkqS1kPbPd7TveP5iyJE0EjAuZQTgFLD2ylzuqKfdKlfG/eSrtxUkn" crossorigin="anonymous">
	<link rel="stylesheet" href="css/modelstyle.css">
	<link href="https://cdnjs.cloudflare.com/ajax/libs/video.js/7.0.0/video-js.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/video.js/7.0.0/video.min.js"></script>
</head>

<body>
	<div id="controls">
		<form method="GET">
			<div class="container">
				<div class="row">
					<div class="col-md-6">
						<button onclick="tracker.squatCounter = 0">Reset Counter</button>
					</div>
				</div>
			</div>
		</form>	

		<button id="btn_toggle_video" class="btn btn-secondary">VIDEO ON/OFF</button>
		<button id="btn_toggle_debug" class="btn btn-secondary">DEBUG ON/OFF</button>



	</div>
	<button id="btn_toggle_controls" class="btn btn-primary">SHOW/HIDE CONTROLS</button>

	<div class="mt-2 text-center" id="status"></div>

	<div id="wrapper" class="container-fluid">		
	  <canvas id="canvas"></canvas>
	  <video id="video" class="video-js vjs-fluid vjs-default-skin" preload="metadata">
	  	<source src="">
	  </video>
	  <div id="info_debug"></div>
	  <div id="info_counter"></div>
	</div>
	<div id="view_3d"></div>
	<div class="footer">SF HACKS 2025 Project</div>

	<!-- Load Tensor Flow -->
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

	<!-- Load three.js -->
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
	<!-- Load scatter-gl.js -->
	<script src="https://cdn.jsdelivr.net/npm/scatter-gl@0.0.13/lib/scatter-gl.min.js"></script>

	<!-- Load tracker.js and app.js-->
	<script src="js/app.js"></script>
	<script src="js/tracker.js"></script>
	<script src="js/sound.js"></script>

	<script>
		let source = 'camera'; // camera|video|stream
		let model = 'BlazePoseFull';

		// Set model and 3D options
		tracker.setModel(model);
		tracker.enable3D = true;
		tracker.autofit = true;

		// Set exercise type based on page
		const page = window.location.pathname;
		if (page.includes("modelJJ")) {
			tracker.setExercise('jumping_jack');
		} else if (page.includes("modelSQ")) {
			tracker.setExercise('squat');
		} else if (page.includes("modelLR")) {
			tracker.setExercise('leg_raise');
		}

		// Initialize UI and sound
		app.init();
		soundPlayer.preload();

		// Setup tracker hooks
		tracker.on('statuschange', msg => app.updateStatus(msg));
		tracker.on('beforeupdate', poses => {
			app.updateDebug(poses);
			app.updateCounter(poses);
		});

		// STEP 1: Disable AI temporarily
		tracker.enableAI = false;

		// STEP 2: Start camera immediately (shows live video)
		tracker.run(source);

		// STEP 3: Play intro, THEN enable AI tracking
		soundPlayer.playIntro(() => {
			console.log('Intro done. Starting AI tracking.');
			tracker.enableAI = true;
		});
	</script>

	<script>
		const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
		const recognition = new SpeechRecognition();
		recognition.continuous = true;
		recognition.interimResults = false;
		recognition.lang = 'en-US';

		let shouldListen = true;

		// Preload stopping sound
		const stopAudio = new Audio('/sounds/stopping_exercise.mp3');

		recognition.onresult = function(event) {
			const transcript = event.results[event.results.length - 1][0].transcript.trim().toLowerCase();
			console.log("Heard:", transcript);

			if (transcript.includes("stop")) {
				shouldListen = false;
				recognition.stop();
				console.log("Voice command 'stop' detected. Playing sound and redirecting...");

				// Optional canvas message
				const ctx = document.getElementById('canvas')?.getContext('2d');
				if (ctx) {
					ctx.fillStyle = 'red';
					ctx.font = '24px Arial';
					ctx.fillText('Stopping...', 30, 130);
				}

				// Play the sound
				stopAudio.currentTime = 0;
				stopAudio.play();

				// Wait for audio duration or fixed delay before redirecting
				setTimeout(() => {
					window.location.href = '/exerciseSelection';
				}, 3000); // match the length of your MP3 or adjust as needed
			}
		};

		recognition.onerror = function(event) {
			console.warn("Speech recognition error:", event.error);
		};

		recognition.onend = function() {
			if (shouldListen) recognition.start();
		};

		window.addEventListener('load', () => {
			recognition.start();
		});
	</script>



</body>
</html>