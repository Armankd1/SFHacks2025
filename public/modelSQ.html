<html>
<head>
	<meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Squats</title>
	<meta name="description"
          content="JS AI Body Tracker - javascript library implementing body tracking with ANN models: MoveNet, PoseNet and Blase Pose"/>
    <meta name="robots" content="index, follow"/>
    <meta name="og:site_name" content="JS AI Body Tracker"/>
    <meta name="og:type" content="website"/>
    <meta name="og:title" content="JS AI Body Tracker"/>
    <meta name="og:description"
          content="JS AI Body Tracker - javascript library implementing body tracking with ANN models: MoveNet, PoseNet and Blase Pose"/>
    <meta name="og:url" content="https://szczyglis.dev/js-ai-body-tracker"/>

	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" integrity="sha384-zCbKRCUGaJDkqS1kPbPd7TveP5iyJE0EjAuZQTgFLD2ylzuqKfdKlfG/eSrtxUkn" crossorigin="anonymous">
	<link rel="stylesheet" href="css/modelstyle.css">
	<link href="https://cdnjs.cloudflare.com/ajax/libs/video.js/7.0.0/video-js.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/video.js/7.0.0/video.min.js"></script>
</head>

<body>
	<div class="gh">
	    <div class="demo version-section"><a target="_blank" href="https://github.com/szczyglis-dev/js-ai-body-tracker"
	                                         class="github-corner" aria-label="View source on GitHub">
	            <svg width="80" height="80" viewBox="0 0 250 250"
	                 style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
	                <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
	                <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
	                      fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
	                <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
	                      fill="currentColor" class="octo-body"></path>
	            </svg>
	        </a>
	    </div>
	</div>

	<div id="controls">
		<form method="GET">
			<div class="container">
				<div class="row">
					<div class="col-md-6">
						<button onclick="tracker.squatCounter = 0">Reset Counter</button>
					</div>
				</div>
			</div>
		</form>	

		<button id="btn_toggle_video" class="btn btn-secondary">VIDEO ON/OFF</button>
		<button id="btn_toggle_debug" class="btn btn-secondary">DEBUG ON/OFF</button>



	</div>
	<button id="btn_toggle_controls" class="btn btn-primary">SHOW/HIDE CONTROLS</button>

	<div class="mt-2 text-center" id="status"></div>

	<div id="wrapper" class="container-fluid">		
	  <canvas id="canvas"></canvas>
	  <video id="video" class="video-js vjs-fluid vjs-default-skin" preload="metadata">
	  	<source src="">
	  </video>
	  <div id="info_debug"></div>
	  <div id="info_counter"></div>
	</div>
	<div id="view_3d"></div>
	<div class="footer">SF HACKS 2025 Project</div>

	<!-- Load Tensor Flow -->
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

	<!-- Load three.js -->
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
	<!-- Load scatter-gl.js -->
	<script src="https://cdn.jsdelivr.net/npm/scatter-gl@0.0.13/lib/scatter-gl.min.js"></script>

	<!-- Load tracker.js and app.js-->
	<script src="js/app.js"></script>
	<script src="js/tracker.js"></script>
	<script src="js/sound.js"></script>

	<script>
		let source = 'camera'; // camera|video|stream
		let model = 'BlazePoseFull';

		// Set model and 3D options
		tracker.setModel(model);
		tracker.enable3D = true;
		tracker.autofit = true;

		// Set exercise type based on page
		const page = window.location.pathname;
		if (page.includes("modelJJ")) {
			tracker.setExercise('jumping_jack');
		} else if (page.includes("modelSQ")) {
			tracker.setExercise('squat');
		} else if (page.includes("modelLR")) {
			tracker.setExercise('leg_raise');
		}

		// Initialize UI and sound
		app.init();
		soundPlayer.preload();

		// Setup tracker hooks
		tracker.on('statuschange', msg => app.updateStatus(msg));
		tracker.on('beforeupdate', poses => {
			app.updateDebug(poses);
			app.updateCounter(poses);
		});

		// STEP 1: Disable AI temporarily
		tracker.enableAI = false;

		// STEP 2: Start camera immediately (shows live video)
		tracker.run(source);

		// STEP 3: Play intro, THEN enable AI tracking
		soundPlayer.playIntro(() => {
			console.log('Intro done. Starting AI tracking.');
			tracker.enableAI = true;
		});
	</script>

    <script>
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        let shouldListen = true;

        recognition.onresult = function(event) {
            const transcript = event.results[event.results.length - 1][0].transcript.trim().toLowerCase();
            console.log("Heard:", transcript);

            if (transcript.includes("stop")) {
                shouldListen = false;
                recognition.stop();
                console.log("Voice command 'stop' detected. Redirecting in 3 seconds...");
                const ctx = document.getElementById('canvas')?.getContext('2d');
                if (ctx) {
                    ctx.fillStyle = 'red';
                    ctx.font = '24px Arial';
                    ctx.fillText('Stopping...', 30, 130);
                }
                setTimeout(() => {
                    window.location.href = '/exerciseSelection';
                }, 3000);
            }
        };

        recognition.onerror = function(event) {
            console.warn("Speech recognition error:", event.error);
        };

        recognition.onend = function() {
            if (shouldListen) recognition.start();
        };

        window.addEventListener('load', () => {
            recognition.start();
        });
    </script>


</body>
</html>